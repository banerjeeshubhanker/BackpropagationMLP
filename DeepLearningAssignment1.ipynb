{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parliamentary-favorite",
   "metadata": {},
   "source": [
    "# # Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-rating",
   "metadata": {},
   "source": [
    "Logistic regression is a machine learning algorithm that build on the linear regression by introducing non-linearity in the form a sigmoid function to it. Essentially speaking the output of a linear regressor which can be described as a linear combination of features and parameters is fed to a sigmoid function and the a probability measure is calculated. The non-linearity introduced in the form of sigmoid function helps in learning non-linear decision boundaries and ouput of the sigmoid serves as a measure of the probability of a class. In this implementation I have used an iterative gradient based algorithm, known as the gradient descent in order to optimize the parameters of the sigmoid function in order to learn the most optimal decsision boundary on the basis  of the given data. I have specifically used cross-entropy to calculate the loss between the predicted output and the actual output and tried to minimize that loss by using a variant of gradient descent known as stochastic gradient descent which minimizes the loss over a random datapoint from the training data in each epoch to learn the most optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passive-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "physical-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.weights = np.random.random_sample(size = X_train.shape[1])\n",
    "        self.bias = np.random.random_sample(size = 1)\n",
    "        self.threshold = math.pow(10,-8)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return 1/(1+math.exp(-1*(np.matmul(self.weights, x.T)+self.bias)))\n",
    "    \n",
    "    def evaluate(self,x):\n",
    "        if 1/(1+math.exp(-1*(np.matmul(self.weights, x.T)+self.bias)))>0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def cost(self, y_pred, y_actual):\n",
    "        cost = y_actual*(math.log(y_pred,10))+(1-y_actual)*(math.log((1-y_pred),10))\n",
    "        return cost\n",
    "    \n",
    "    def train(self, n_epochs, learning_rate):\n",
    "        past_cost = 0\n",
    "        prsent_cost = 0\n",
    "        for i in range(n_epochs):\n",
    "            res = (self.X_train.shape[0])\n",
    "            random_datapoint = random.randint(0,res-1)\n",
    "            y_pred = self.predict(self.X_train[random_datapoint,:])\n",
    "            y_actual = self.Y_train[random_datapoint]\n",
    "            present_cost = self.cost(y_pred = y_pred, y_actual = y_actual)\n",
    "            if abs(present_cost - past_cost) > self.threshold:\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] = self.weights[j] - learning_rate*((self.predict(self.X_train[random_datapoint,:])-self.Y_train[random_datapoint])*(self.X_train[random_datapoint,j]))\n",
    "                self.bias = self.bias - learning_rate*(self.predict(self.X_train[random_datapoint,:])-self.Y_train[random_datapoint])\n",
    "                past_cost = present_cost\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "contained-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"blobs250.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "worse-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.loc[:,[\"Class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "induced-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, ['X0', 'X1', 'X2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "loving-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "premium-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-canberra",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-logan",
   "metadata": {},
   "source": [
    "I have used my own data split function written using numpy and not used scikitlearn's implementation. This splits the data in 85-15-15 ratio for training-test-validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X,Y):\n",
    "    indices = np.random.choice(range(X.shape[0]), int(0.85*X.shape[0]), replace=False)\n",
    "    indices_validation = np.random.choice(indices, size=int(0.15*X.shape[0]), replace = False)\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    X_valid = []\n",
    "    Y_valid = []\n",
    "    for i in range(len(X)):\n",
    "        if i in indices_validation:\n",
    "            X_valid.append(X[i])\n",
    "            Y_valid.append(Y[i])\n",
    "        elif i in indices and i not in indices_validation:\n",
    "            X_train.append(X[i])\n",
    "            Y_train.append(Y[i])\n",
    "        else:\n",
    "            X_test.append(X[i])\n",
    "            Y_test.append(Y[i])\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "    X_valid = np.array(X_valid)\n",
    "    Y_valid = np.array(Y_valid)\n",
    "    return X_train, Y_train, X_test, Y_test, X_valid, Y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "assigned-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = data_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cubic-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = LogisticRegression(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demographic-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.train(n_epochs = 50, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "previous-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-47d486ab2c70>:4: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  valid_error = valid_error + abs(res-np.asscalar(Y_valid[i]))\n"
     ]
    }
   ],
   "source": [
    "valid_error = 0\n",
    "for i in range(len(X_valid)):\n",
    "    res = obj.evaluate(X_valid[i])\n",
    "    valid_error = valid_error + abs(res-np.asscalar(Y_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "equipped-guinea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tutorial-benjamin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-0c5557611724>:4: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  test_error = test_error + abs(res-np.asscalar(Y_test[i]))\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "for i in range(len(X_test)):\n",
    "    res = obj.evaluate(X_test[i])\n",
    "    test_error = test_error + abs(res-np.asscalar(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "connected-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-craft",
   "metadata": {},
   "source": [
    "In the cells above the logistic regression algorithm was used for learning a classifier on the blobs250 dataset. The training data consisted of 175 samples, the test data was made up of 38 samples and 37 samples made up the validation data. The model was trained for 50 epochs using a learning rate of 0.01 and the model was able to achieve a 100% accuracy score on test and validation sets. Thus, logistiic regression was able to find the perfect fit for this dataset. I observed that the model required few epochs and could get excellent results with a high learning rate, and from this observation I conclude that the decision boundary is approximately linear in nature and therefore fitting it is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "large-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"moons400(1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "instrumental-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.loc[:,[\"Class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "faced-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, ['X0', 'X1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "disciplinary-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "vanilla-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "experienced-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = data_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "minimal-basics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "fewer-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "wooden-cancer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 2)"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minor-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = LogisticRegression(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "vital-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.train(n_epochs = 1000, learning_rate = 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cordless-chaos",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-47d486ab2c70>:4: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  valid_error = valid_error + abs(res-np.asscalar(Y_valid[i]))\n"
     ]
    }
   ],
   "source": [
    "valid_error = 0\n",
    "for i in range(len(X_valid)):\n",
    "    res = obj.evaluate(X_valid[i])\n",
    "    valid_error = valid_error + abs(res-np.asscalar(Y_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "registered-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acknowledged-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-0c5557611724>:4: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  test_error = test_error + abs(res-np.asscalar(Y_test[i]))\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "for i in range(len(X_test)):\n",
    "    res = obj.evaluate(X_test[i])\n",
    "    test_error = test_error + abs(res-np.asscalar(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "recent-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-crisis",
   "metadata": {},
   "source": [
    "In the cells above the logistic regression algorithm was used for learning a classifier on the blobs250 dataset. The training data consisted of 280 samples, the test data was made up of 60 samples and 60 samples made up the validation data. The validation set was used to optimize the hyperparameter and the number of epochs for which this model is to be trained. It was found that when the model was trained for 1000 epochs using a learning rate of 0.09 then model was able to achieve the best performance with 90% accuracy score on test and approximately 92% on the validation set. The higher number of epochs show that the decision boundary is more difficult and possibly non-linear in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-potter",
   "metadata": {},
   "source": [
    "## Shallow NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-elizabeth",
   "metadata": {},
   "source": [
    "Neural network follows from the connectionist approach to computing. In neural networks multiple neurons are connected each by weighted connections. It can essentially be thought of as a graph with directed weighted edges. Taking this this approach, the logistic regression algorithm used above can also be thought of as a graph with the output node connected to all the input nodes where each input node represents a afeature of the input vector. The essential difference is that in a neural network the inputs are not directly connected to the output but instead to other nodes which essentially transform the features by applying a linear transformation with a weights followed by non-linearities, the outputs generated by these intermediate nodes are subseque ntly connected to other intermediate nodes by weighted connections and this goes on till the last intermediate layer which then serves as an input to the output layer with a transformed set of features. The main idea behind this approach is that the features transformed withhin these layers successively capture more important information about the data and thus can enable learning of better decsion boundaries or regressions at the output node. The weights are learned by using an iterative algorithm known as gradient descnet which minimzes the loss or the difference between actual and predicted values as a function of the weights iteratively. I have used stochastic gradient descent in my approach which optimizes the loss over a specific datapoint chosen randomly in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-spokesman",
   "metadata": {},
   "source": [
    "The algorithm supports multiple hidden layers with two types of activation: sigmoid and Relu and multiple nodes in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "knowing-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    ##Intilialization Constructor\n",
    "    def __init__(self, X_train, Y_train, n_hidden_layers, hidden_layers_neurons, n_inputs,activation):\n",
    "        if n_hidden_layers == 0:\n",
    "            raise Exception(\"Sorry, there has to be atleast two layers (one input layer and one hidden layer) in the network\")\n",
    "        elif n_hidden_layers >= 1:\n",
    "            activations = []\n",
    "            z_values = []\n",
    "            weights = []\n",
    "            dl_weights = []\n",
    "            dl_biases = []\n",
    "            dl_z_values = []\n",
    "            dl_activations = []\n",
    "            output_weights = []\n",
    "            biases = []\n",
    "            for i in range(len(hidden_layers_neurons)):\n",
    "                activations.append(np.random.random_sample(size = (hidden_layers_neurons[i],1)))\n",
    "                z_values.append(np.random.random_sample(size = (hidden_layers_neurons[i],1)))\n",
    "                biases.append(np.random.random_sample(size = (hidden_layers_neurons[i],1)))\n",
    "                dl_activations.append(np.random.random_sample(size = (hidden_layers_neurons[i],1)))\n",
    "                dl_z_values.append(np.random.random_sample(size = (hidden_layers_neurons[i],1)))\n",
    "                dl_biases.append(np.random.random_sample(size = (hidden_layers_neurons[i],1)))\n",
    "                if i == 0:\n",
    "                    weights.append(np.random.random_sample(size = (hidden_layers_neurons[i],n_inputs))/1000)\n",
    "                    dl_weights.append(np.random.random_sample(size = (hidden_layers_neurons[i],n_inputs))/1000)\n",
    "                else:\n",
    "                    weights.append(np.random.random_sample(size = (hidden_layers_neurons[i],hidden_layers_neurons[i-1])))\n",
    "                    dl_weights.append(np.random.random_sample(size = (hidden_layers_neurons[i],hidden_layers_neurons[i-1])))\n",
    "            ##Values\n",
    "            self.output_weights_nn = np.random.random_sample(size = (1,hidden_layers_neurons[n_hidden_layers-1]))\n",
    "            self.output_hidden_nn = np.random.random_sample(size = (1,1))\n",
    "            self.output_bias_nn = np.random.random_sample(size = (1,1))\n",
    "            self.output_activation_nn = np.random.random_sample(size = (1,1))\n",
    "            self.weights_nn = weights\n",
    "            self.biases_nn = biases\n",
    "            self.z_values_nn = z_values\n",
    "            self.activations_nn = activations\n",
    "            self.X_train = X_train\n",
    "            self.Y_train = Y_train\n",
    "            self.neurons_per_hidden_layer_nn = hidden_layers_neurons\n",
    "            self.number_of_hidden_layers_nn = n_hidden_layers\n",
    "            self.n_inputs_nn = n_inputs\n",
    "            ##Derivatives\n",
    "            self.dl_output_weights_nn = np.random.random_sample(size = (1,hidden_layers_neurons[n_hidden_layers-1]))\n",
    "            self.dl_output_hidden_nn = np.random.random_sample(size = (1,1))\n",
    "            self.dl_output_bias_nn = np.random.random_sample(size = (1,1))\n",
    "            self.dl_output_activation_nn = np.random.random_sample(size = (1,1))\n",
    "            self.dl_weights_nn = dl_weights\n",
    "            self.dl_biases_nn = dl_biases\n",
    "            self.dl_z_values_nn = dl_z_values\n",
    "            self.dl_activations_nn = dl_activations\n",
    "            self.activation_type = activation\n",
    "            \n",
    "    ##The output node, it uses sigmoid to give binary probabilities\n",
    "    def output(self,res):\n",
    "        if res < 0:\n",
    "            return 1 - 1 / (1 + np.exp(res))\n",
    "        return 1 / (1 + np.exp(-res))\n",
    "        \n",
    "    ##Activation Function\n",
    "    def sigmoid(self,res):\n",
    "        if self.activation_type == \"sigmoid\":\n",
    "            if res < 0:\n",
    "                return 1 - 1 / (1 + np.exp(res))\n",
    "            return 1 / (1 + np.exp(-res))\n",
    "        elif self.activation_type == \"relu\":\n",
    "            if res>6:\n",
    "                res = 6\n",
    "            y1 = ((res > 0) * res)                                                 \n",
    "            y2 = ((res <= 0) * res * 0.01)                                         \n",
    "            return y1 + y2  \n",
    "\n",
    "            \n",
    "    ##Derivative of activation function        \n",
    "    def sigmoid_derivative(self,res):\n",
    "        if self.activation_type == \"sigmoid\":\n",
    "            return self.sigmoid(res)*(1-self.sigmoid(res))\n",
    "        elif self.activation_type == \"relu\":\n",
    "            if res < 0:\n",
    "                return 0.01\n",
    "            else:\n",
    "                return 1\n",
    "            \n",
    "    ##Forward Propagation Function        \n",
    "    def forward(self,X):\n",
    "        dim = X.shape[0]\n",
    "        X = X.reshape(1,dim)\n",
    "        hidden_state = X\n",
    "        for i in range(self.number_of_hidden_layers_nn):\n",
    "            hidden_state = np.matmul(hidden_state,self.weights_nn[i].T) + self.biases_nn[i].T\n",
    "            self.z_values_nn[i] = hidden_state.T\n",
    "            self.activations_nn[i] = np.array([self.sigmoid(xi) for xi in hidden_state[0]]).reshape(1,self.neurons_per_hidden_layer_nn[i]).T\n",
    "            hidden_state = self.activations_nn[i].T\n",
    "        self.output_hidden_nn = np.dot(self.output_weights_nn,self.activations_nn[self.number_of_hidden_layers_nn-1]) + self.output_bias_nn\n",
    "        self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n",
    "        return self.output_activation_nn\n",
    "     \n",
    "    ##Backpropagation Function    \n",
    "    def backward(self,Y,X,learning_rate):\n",
    "        dim = X.shape[0]\n",
    "        X = X.reshape(1,dim)\n",
    "        ##Derivatives of last layer\n",
    "        self.dl_output_hidden_nn = self.output_activation_nn - Y\n",
    "        self.dl_output_weights_nn = self.output_hidden_nn * (self.activations_nn[self.number_of_hidden_layers_nn-1].T)\n",
    "        self.dl_output_bias_nn = self.dl_output_hidden_nn\n",
    "        self.output_weights_nn = self.output_weights_nn - (learning_rate*self.dl_output_weights_nn)\n",
    "        self.output_bias_nn =  self.output_bias_nn - (learning_rate*self.dl_output_bias_nn)\n",
    "        self.output_hidden_nn = self.output_hidden_nn - (learning_rate*self.dl_output_hidden_nn)\n",
    "        \n",
    "        ##Looping back through the hidden layers, with conditions essentially checking how many layers are present\n",
    "        for i in range(self.number_of_hidden_layers_nn-1,-1,-1):\n",
    "            \n",
    "            ## last Hidden layer with hidden layer to the left\n",
    "            if i == self.number_of_hidden_layers_nn-1 and i != 0:\n",
    "                res = self.z_values_nn[i].reshape(1,self.neurons_per_hidden_layer_nn[i])\n",
    "                res = res[0]\n",
    "                res = np.array([self.sigmoid_derivative(xi) for xi in res])\n",
    "                for j in range(self.neurons_per_hidden_layer_nn[self.number_of_hidden_layers_nn-1]):\n",
    "                    sum1 = 0\n",
    "                    sum1 = sum1 + self.dl_output_hidden_nn*self.output_weights_nn[0,j]\n",
    "                    res[j] = res[j]*sum1\n",
    "                res = np.array(res).reshape(self.neurons_per_hidden_layer_nn[i],1)\n",
    "                \n",
    "                ##Derivative wrt hidden state\n",
    "                self.dl_z_values_nn[self.number_of_hidden_layers_nn-1] = res\n",
    "                \n",
    "                ##Derivative wrt biases\n",
    "                self.dl_biases_nn[self.number_of_hidden_layers_nn-1] = res\n",
    "                \n",
    "                ##Derivative wrt weights\n",
    "                self.dl_weights_nn[i] = np.matmul(self.dl_z_values_nn[self.number_of_hidden_layers_nn-1],self.activations_nn[i-1].T)\n",
    "                \n",
    "                ##Updates using learning rate\n",
    "                self.z_values_nn[i] = self.z_values_nn[i]-(learning_rate*self.dl_z_values_nn[i])\n",
    "                self.biases_nn[i] = self.biases_nn[i]-(learning_rate*self.dl_biases_nn[i])\n",
    "                self.weights_nn[i] = self.weights_nn[i]-(learning_rate*self.dl_weights_nn[i])\n",
    "            \n",
    "            ## Last hidden layer with input on the left\n",
    "            elif i == self.number_of_hidden_layers_nn-1 and i == 0:\n",
    "                res = self.z_values_nn[i].reshape(1,self.neurons_per_hidden_layer_nn[i])\n",
    "                res = res[0]\n",
    "                res = np.array([self.sigmoid_derivative(xi) for xi in res])\n",
    "                for j in range(self.neurons_per_hidden_layer_nn[self.number_of_hidden_layers_nn-1]):\n",
    "                    sum1 = 0\n",
    "                    sum1 = sum1 + self.dl_output_hidden_nn*self.output_weights_nn[0,j]\n",
    "                    res[j] = res[j]*sum1\n",
    "                res = np.array(res).reshape(self.neurons_per_hidden_layer_nn[i],1)\n",
    "                self.dl_z_values_nn[self.number_of_hidden_layers_nn-1] = res\n",
    "                self.dl_biases_nn[self.number_of_hidden_layers_nn-1] = res\n",
    "                self.dl_weights_nn[i] = np.matmul(self.dl_z_values_nn[self.number_of_hidden_layers_nn-1],X)\n",
    "                self.z_values_nn[i] = self.z_values_nn[i]-(learning_rate*self.dl_z_values_nn[i])\n",
    "                self.biases_nn[i] = self.biases_nn[i]-(learning_rate*self.dl_biases_nn[i])\n",
    "                self.weights_nn[i] = self.weights_nn[i]-(learning_rate*self.dl_weights_nn[i])\n",
    "            \n",
    "            ## Middle hidden layer with input to the left\n",
    "            elif i < self.number_of_hidden_layers_nn-1 and i == 0:\n",
    "                res = self.z_values_nn[i].reshape(1,self.neurons_per_hidden_layer_nn[i])\n",
    "                res = res[0]\n",
    "                res = np.array([self.sigmoid_derivative(xi) for xi in res])\n",
    "                weights = self.weights_nn[i+1]\n",
    "                hidden = self.z_values_nn[i+1]\n",
    "                hidden = hidden.T\n",
    "                hidden = hidden[0]\n",
    "                weights = weights.T\n",
    "                for j in range(len(weights)):\n",
    "                    intermediate = np.dot(hidden,weights[j])\n",
    "                    res[j] = res[j]*intermediate\n",
    "                res = np.array(res).reshape(self.neurons_per_hidden_layer_nn[i],1)\n",
    "                self.dl_z_values_nn[self.number_of_hidden_layers_nn-1] = res\n",
    "                self.dl_biases_nn[self.number_of_hidden_layers_nn-1] = res\n",
    "                self.dl_weights_nn[i] = np.matmul(self.dl_z_values_nn[i],X)\n",
    "                self.z_values_nn[i] = self.z_values_nn[i]-(learning_rate*self.dl_z_values_nn[i])\n",
    "                self.biases_nn[i] = self.biases_nn[i]-(learning_rate*self.dl_biases_nn[i])\n",
    "                self.weights_nn[i] = self.weights_nn[i]-(learning_rate*self.dl_weights_nn[i])\n",
    "            \n",
    "            ##Middle hidden layer with hidden layer to the left \n",
    "            elif i < self.number_of_hidden_layers_nn-1 and i != 0:\n",
    "                res = self.z_values_nn[i].reshape(1,self.neurons_per_hidden_layer_nn[i])\n",
    "                res = res[0]\n",
    "                res = np.array([self.sigmoid_derivative(xi) for xi in res])\n",
    "                weights = self.weights_nn[i+1]\n",
    "                hidden = self.z_values_nn[i+1]\n",
    "                hidden = self.z_values_nn[i+1]\n",
    "                hidden = hidden.T\n",
    "                hidden = hidden[0]\n",
    "                weights = weights.T\n",
    "                for j in range(len(weights)):\n",
    "                    intermediate = np.dot(hidden,weights[j])\n",
    "                    res[j] = res[j]*intermediate\n",
    "                res = np.array(res).reshape(self.neurons_per_hidden_layer_nn[i],1)\n",
    "                self.dl_z_values_nn[i] = res\n",
    "                self.dl_biases_nn[i] = res\n",
    "                self.dl_weights_nn[i] = np.matmul(self.dl_z_values_nn[i],self.activations_nn[i-1].T)\n",
    "                self.z_values_nn[i] = self.z_values_nn[i]-(learning_rate*self.dl_z_values_nn[i])\n",
    "                self.biases_nn[i] = self.biases_nn[i]-(learning_rate*self.dl_biases_nn[i])\n",
    "                self.weights_nn[i] = self.weights_nn[i]-(learning_rate*self.dl_weights_nn[i])\n",
    "            \n",
    "    ##Training function            \n",
    "    def train(self,learning_rate,n_epochs):\n",
    "        full_loss = []\n",
    "        for i in range(n_epochs):\n",
    "            random_index = randrange(len(self.X_train))\n",
    "            predicted = self.forward(self.X_train[random_index])\n",
    "            actual_Y = self.Y_train[random_index]\n",
    "            loss = -1*(actual_Y*np.log(predicted+0.0000001)+(1-actual_Y)*np.log(1-predicted+0.00000001))\n",
    "            full_loss.append(loss)\n",
    "            self.backward(self.Y_train[random_index],self.X_train[random_index],learning_rate)\n",
    "\n",
    "        x = range(n_epochs)\n",
    "        plt.plot(x, full_loss)\n",
    "        plt.savefig('test.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def evaluate(self,X):\n",
    "        return self.forward(X)\n",
    "                \n",
    "                    \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "simplified-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"blobs250.csv\")\n",
    "Y = data.loc[:,[\"Class\"]]\n",
    "X = data.loc[:, ['X0', 'X1', 'X2']]\n",
    "Y = Y.values.flatten()\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "plastic-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = data_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "broke-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = NN(X_train,Y_train,1,[4],3,\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "banner-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj.train(0.0001,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-simpson",
   "metadata": {},
   "source": [
    "Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "approximate-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n",
      "<ipython-input-584-7926af1d4fe8>:7: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  valid_error = valid_error + abs(predicted - np.asscalar(Y_valid[i]))\n"
     ]
    }
   ],
   "source": [
    "valid_error = 0\n",
    "for i in range(len(X_valid)):\n",
    "    res = obj.evaluate(X_valid[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    valid_error = valid_error + abs(predicted - np.asscalar(Y_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "russian-portal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "infrared-alert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n",
      "<ipython-input-586-b6a4fcfc7636>:7: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  test_error = test_error + abs(predicted - np.asscalar(Y_test[i]))\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "for i in range(len(X_test)):\n",
    "    res = obj.evaluate(X_test[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    test_error = test_error + abs(predicted - np.asscalar(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "prostate-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-leeds",
   "metadata": {},
   "source": [
    "The neural network was trained with one hidden layer with 4 neurons for this experiment. It was trained for 100000 epochs with a learning rate of 0.0001 a validation and test accuracy of 100% was achieved. The training data consisted of 175 samples, the test data was made up of 38 samples and 37 samples made up the validation data. The validation set was used to tune in the hyperparameters. This shows that the model was able to learn the decision boundary for blobs250 dataset perfectly. The loss curve shows convergence after a few iterations.This is not unexpected as the neural network can learn non-linear decsion decision boundaries and as hypothesized earlier this is approximately a linear boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "precise-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"moons400(1).csv\")\n",
    "Y = data.loc[:,[\"Class\"]]\n",
    "X = data.loc[:, ['X0', 'X1']]\n",
    "X = X.values\n",
    "Y = Y.values.flatten()\n",
    "X_train, Y_train, X_test, Y_test, X_valid, Y_valid = data_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "banner-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = NN(X_train,Y_train,1,[1],2,\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "accepted-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj.train(0.0001,200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-violation",
   "metadata": {},
   "source": [
    "Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "foreign-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n",
      "<ipython-input-639-7926af1d4fe8>:7: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  valid_error = valid_error + abs(predicted - np.asscalar(Y_valid[i]))\n"
     ]
    }
   ],
   "source": [
    "valid_error = 0\n",
    "for i in range(len(X_valid)):\n",
    "    res = obj.evaluate(X_valid[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    valid_error = valid_error + abs(predicted - np.asscalar(Y_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "revolutionary-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "dutch-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n",
      "<ipython-input-641-b6a4fcfc7636>:7: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  test_error = test_error + abs(predicted - np.asscalar(Y_test[i]))\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "for i in range(len(X_test)):\n",
    "    res = obj.evaluate(X_test[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    test_error = test_error + abs(predicted - np.asscalar(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "swedish-warrant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-barrel",
   "metadata": {},
   "source": [
    "On the basis of above experiments when the neural network with one hidden layer was trained for 200000 epochs with a learning rate of 0.0001 a validation accuracy 82% and test accuracy of 74% was achieved. The training data consisted of 280 samples, the test data was made up of 60 samples and 60 samples made up the validation data. The validation set was used to tune in the hyperparameters. The results were lower than that for logistic regression, many attempts were made to further tune the hyperparameters for the given task but this is best accuracy that could be achieved. training for more epochs could possibly be a solution to this problem Furthermore, a convergence around 0.6 was observed for the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-immunology",
   "metadata": {},
   "source": [
    "## CIFAR-10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-swing",
   "metadata": {},
   "source": [
    "In this experiment I trained my model on 5000 images of cat and truck from the CIFAR-10 dataset. A label of 1 was assigned to truck and a label of 0 was assigned to cat. One hidden with 20 neurons was used for this experiment. The test dataset consisted of 1000 images of cats and trucks and 986 images made up the validation dataset. Each image was turned into a vector of 1024 floats by averaging over the three channels and normalized by 255 to retrict the values to [0,1]. The validation dataset was used to yune the hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "marine-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "ancient-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):   \n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:       \n",
    "        dict = pickle.load(fo, encoding='bytes')   \n",
    "        return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "julian-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/shubhanker/Desktop/Doubts/Deep Learning/cifar-10-python/cifar-10-batches-py/\"\n",
    "for i in range(1, 6):\n",
    "    file = directory+\"data_batch_\"+str(i) \n",
    "    dict_data = unpickle(file) \n",
    "    x_data = dict_data[b'data']  \n",
    "    y_data = np.array(dict_data[b\"labels\"])\n",
    "    if i == 1: \n",
    "        x_train = x_data  \n",
    "        y_train = y_data  \n",
    "    else:  \n",
    "        x_train = np.concatenate((x_train, x_data), axis = 0)   \n",
    "        y_train = np.concatenate((y_train, y_data), axis = 0) \n",
    "test_data_file = directory+\"test_batch\" \n",
    "dict_data_test = unpickle(test_data_file)\n",
    "data = dict_data_test[b\"data\"]\n",
    "x_test = data \n",
    "y_test = np.array(dict_data_test[b\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "banner-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_train = []\n",
    "final_y_train = []\n",
    "cat_count = 0\n",
    "truck_count = 0\n",
    "for i in range(len(x_train)):\n",
    "    if cat_count == truck_count and cat_count == 2500:\n",
    "        break\n",
    "    elif cat_count<2500 and y_train[i] == 3:\n",
    "        cat_count+=1\n",
    "        res = x_train[i].reshape(32,32,3)\n",
    "        img = np.mean(res, axis=2)\n",
    "        img = img / 255\n",
    "        img =  img.flatten()\n",
    "        final_x_train.append(img)\n",
    "        final_y_train.append(0)\n",
    "    elif truck_count<2500 and y_train[i] == 9:\n",
    "        truck_count+=1\n",
    "        res = x_train[i].reshape(32,32,3)\n",
    "        img = np.mean(res, axis=2)\n",
    "        img = img / 255\n",
    "        img =  img.flatten()\n",
    "        final_x_train.append(img)\n",
    "        final_y_train.append(1)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "durable-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_test = []\n",
    "final_y_test = []\n",
    "cat_count = 0\n",
    "truck_count = 0\n",
    "for i in range(len(x_test)):\n",
    "    if cat_count == truck_count and cat_count == 500:\n",
    "        break\n",
    "    elif cat_count<500 and y_test[i] == 3:\n",
    "        cat_count+=1\n",
    "        res = x_test[i].reshape(32,32,3)\n",
    "        img = np.mean(res, axis=2)\n",
    "        img = img / 255\n",
    "        img =  img.flatten()\n",
    "        final_x_test.append(img)\n",
    "        final_y_test.append(0)\n",
    "    elif truck_count<500 and y_test[i] == 9:\n",
    "        truck_count+=1\n",
    "        res = x_test[i].reshape(32,32,3)\n",
    "        img = np.mean(res, axis=2)\n",
    "        img = img / 255\n",
    "        img =  img.flatten()\n",
    "        final_x_test.append(img)\n",
    "        final_y_test.append(1)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "quantitative-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_valid = []\n",
    "final_y_valid = []\n",
    "cat_count = 0\n",
    "truck_count = 0\n",
    "for j in range(i,len(x_test)):\n",
    "    if cat_count == truck_count and cat_count == 500:\n",
    "        break\n",
    "    elif cat_count<500 and y_test[j] == 3:\n",
    "        cat_count+=1\n",
    "        res = x_test[j].reshape(32,32,3)\n",
    "        img = np.mean(res, axis=2)\n",
    "        img = img / 255\n",
    "        img =  img.flatten()\n",
    "        final_x_valid.append(img)\n",
    "        final_y_valid.append(0)\n",
    "    elif truck_count<500 and y_test[j] == 9:\n",
    "        truck_count+=1\n",
    "        res = x_test[j].reshape(32,32,3)\n",
    "        img = np.mean(res, axis=2)\n",
    "        img = img / 255\n",
    "        img =  img.flatten()\n",
    "        final_x_valid.append(img)\n",
    "        final_y_valid.append(1)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "northern-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_valid = np.array(final_x_valid)\n",
    "final_y_valid = np.array(final_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "governing-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_train = np.array(final_x_train)\n",
    "final_y_train = np.array(final_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "sustained-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x_test = np.array(final_x_test)\n",
    "final_y_test = np.array(final_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "complex-pleasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj = NN(final_x_train,final_y_train,1,[20],1024,\"sigmoid\")\n",
    "obj.train(0.001,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-fitting",
   "metadata": {},
   "source": [
    "Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "functional-playing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    }
   ],
   "source": [
    "valid_error = 0\n",
    "for i in range(len(final_x_valid)):\n",
    "    res = obj.evaluate(final_x_valid[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    valid_error = valid_error + abs(predicted - final_y_valid[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "abandoned-membership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "applied-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "for i in range(len(final_x_test)):\n",
    "    res = obj.evaluate(final_x_test[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    test_error = test_error + abs(predicted - final_y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "packed-passport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "quality-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy =  (len(final_x_test)-test_error)/len(final_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "refined-fight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-discrimination",
   "metadata": {},
   "source": [
    "An experiment was carried out with one hidden layer with 20 layers, the best results that were obtained on validation dataset came from a model that was trained with a learning rate of 0.001 for 100000 epochs. When tested on the test data the model gave a performance of 72.2%. Thus the model was able to perform decently on this task, however the performance is till below the state of the art for CIFAR-10. The loss curve shows a convergence at around 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "brave-boating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj = NN(final_x_train,final_y_train,3,[10,3,2],1024,\"relu\")\n",
    "obj.train(0.001,30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-canberra",
   "metadata": {},
   "source": [
    "Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "operating-thermal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    }
   ],
   "source": [
    "valid_error = 0\n",
    "for i in range(len(final_x_valid)):\n",
    "    res = obj.evaluate(final_x_valid[i])\n",
    "#     print(res)\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    valid_error = valid_error + abs(predicted - final_y_valid[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "eight-ecuador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "warming-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-573-173b9dbf85d5>:94: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  self.output_activation_nn = self.output(np.asscalar(self.output_hidden_nn))\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "for i in range(len(final_x_test)):\n",
    "    res = obj.evaluate(final_x_test[i])\n",
    "    predicted = 0\n",
    "    if res>0.5:\n",
    "        predicted = 1\n",
    "    test_error = test_error + abs(predicted - final_y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "premium-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-microphone",
   "metadata": {},
   "source": [
    "As an enhancement, I used the relu activation function, this decision was driven by the fact that sigmoid saturates when handling high dimensional inputs and thus learnability of the model is impacted. Furthermore, I also added multiple layers to the model which led to surprisngly lower accuracy of 60%, thus there was a lower performnace achieved by these layers. experiments not shown here were also carried out with just one hidden layer  and the relu activation function but they did not perform as well as expected with accuracies ranging between 60%-62%. The validation set was used to find the best performing model which was tested on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-typing",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-subscription",
   "metadata": {},
   "source": [
    "All the information, code and concepts used in this assignment was drawn from the lectures. The code was relu implementation was drawn from the pytorch documentation of relu6. This was done because relu was overflowing for multiple layers. The code for reading the CIFAR-10 files was taken from https://medium.com/@rhythm10/image-preprocessing-for-cifar-10-dataset-f2b5cdb221bb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
